# -*- coding: utf-8 -*-
"""final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pl7_LbEzsdEakVIxZAdK3ePgWTnC7E6f
"""

%pip install pyspark

%pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images")

# necessary import 
import pyspark.sql.functions as f
from pyspark.ml.image import ImageSchema
from pyspark.ml.linalg import DenseVector, VectorUDT
import numpy as np
from pyspark.sql.functions import col, size
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from pyspark.sql import SparkSession
from pyspark.ml.image import ImageSchema
from pyspark.sql.functions import lit
from pyspark.ml import Pipeline
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.classification import DecisionTreeClassifier
from functools import reduce
from pyspark.mllib.evaluation import MulticlassMetrics

# create a spark session
# Creating SparkSession
spark = (SparkSession
            .builder
            .config('spark.jars.packages', 'databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11')
            .getOrCreate()
)



#Read images and Create training & test DataFrames for transfer learning
malignant_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13403/1/*.png").withColumn("label", lit(1))
benign_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13403/0/*.png").withColumn("label", lit(0))



#Adding more data to our training and testing sets 
m1_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13462/1/*.png").withColumn("label", lit(1))
b1_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13462/0/*.png").withColumn("label", lit(0))
malignant_df = malignant_df.unionAll(m1_df)
benign_df = benign_df.unionAll(b1_df)

m2_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13459/1/*.png").withColumn("label", lit(1))
b2_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13459/0/*.png").withColumn("label", lit(0))
malignant_df = malignant_df.unionAll(m2_df)
benign_df = benign_df.unionAll(b2_df)

m3_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13460/1/*.png").withColumn("label", lit(1))
b3_df = spark.read.format("image").load("./breast-histopathology-images/IDC_regular_ps50_idx5/13460/0/*.png").withColumn("label", lit(0))
malignant_df = malignant_df.unionAll(m3_df)
benign_df = benign_df.unionAll(b3_df)

malignant_train, malignant_test = malignant_df.randomSplit([0.6, 0.4])
benign_train, benign_test = benign_df.randomSplit([0.6, 0.4])

ImageSchema.imageFields

#dataframe for training a classification model
train_df = malignant_train.unionAll(benign_train)

#dataframe for testing the classification model
test_df = malignant_test.unionAll(benign_test)


# Visualizing microscope slides 
#for img in train_df.select(col('image').getItem('origin')).rdd.flatMap(lambda x:x).collect():
#  img = mpimg.imread(img)
#  imgplot = plt.imshow(img)
#  plt.show()

# Vectorizing image for feature generation. Source: https://stackoverflow.com/questions/69205589/how-preprocess-image-using-pyspark
img2vec = f.udf(lambda x: DenseVector(ImageSchema.toNDArray(x).flatten()), VectorUDT())

train_df = train_df.withColumn('features', img2vec("image"))
test_df = test_df.withColumn('features', img2vec("image"))

# Testing various classification models
lr = LogisticRegression(maxIter=5, labelCol="label", regParam=0.01)
dt = DecisionTreeClassifier(labelCol='label', featuresCol='features', maxDepth=10)
rf = RandomForestClassifier(labelCol='label', featuresCol='features', numTrees=40)


sparkdn = Pipeline(stages=[lr])
spark_model = sparkdn.fit(train_df)

transformed_test_data = spark_model.transform(test_df)
transformed_test_data.cache()

# Generating performance metrics for our model 
preds_and_labels = transformed_test_data.select("prediction", "label").rdd.map(lambda x: (float(x[0]), float(x[1])))
metrics = MulticlassMetrics(preds_and_labels)
precision = metrics.precision(1.0)
recall = metrics.recall(1.0)
f_measure = metrics.fMeasure(1.0)
conf_matrix = metrics.confusionMatrix().toArray()

print("Precision:", precision)
print("Recall:", recall)
print("F-measure:", f_measure)
print(conf_matrix)
